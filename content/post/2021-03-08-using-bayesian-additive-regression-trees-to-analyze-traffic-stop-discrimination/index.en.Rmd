---
title: Using Bayesian Additive Regression Trees to Analyze Traffic Stop Discrimination
author: ''
date: '2021-03-08'
slug: using-bayesian-additive-regression-trees-to-analyze-traffic-stop-discrimination
categories:
  - bayesian analysis
  - traffic stops
  - Bayesian Additive Regression Trees
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-03-08T19:22:36-05:00'
featured: no
image:
  caption: '<span>Photo by <a href="https://unsplash.com/@gerandeklerk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Geran de Klerk</a> on <a href="https://unsplash.com/s/photos/forest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>'
  focal_point: ''
  preview_only: no
projects: []
links:
- icon: github
  icon_pack: fab
  name: Github
  url: https://github.com/shanejorr/shanes-site/blob/main/content/post/2021-03-08-using-bayesian-additive-regression-trees-to-analyze-traffic-stop-discrimination/index.en.Rmd
draft: yes
---

```{r setup, echo = F}
knitr::opts_chunk$set(echo = T,
                      message = F,
                      warning = F,
                      error = F)
```

```{r importLibraries}
library(glue)
library(vroom)
library(modelr)
library(tidycensus)
library(lubridate)
library(highcharter)
library(scales)
library(widgetframe)
library(suncalc)
library(tigris)
library(sf)
library(BART)
library(tidybayes)
library(rstanarm)
library(tidyverse)

options(mc.cores = parallel::detectCores())
```

```{r}
# create ggplot theme for this post
post_theme <- theme_minimal() +
  theme(legend.position = 'bottom',
        plot.title = element_text(size = 11),
        plot.subtitle = element_text(size = 10),
        axis.title = element_text(size = 10))

theme_set(post_theme)

# standard credits to all to all high charts plots

# credits to be used on all plots
add_credits <- function(hc) {
  hc %>%
    hc_credits(
      enabled = TRUE,
      text = "Data source: The Stanford Open Policing Project | US Census Bureau Pop. Estimates",
      href = FALSE
  )
}

scatter_stops_per <- function(df, second_race, plot_title, y_title) {
  
  # scatter plot of stops per 100 residents for white and black / hispanic drivers
  # second_race is the race to compare with white
  
  # max axis point
  max_point <- 45
  
  # find out if white or minority group is higher, used for colors above or below line
  df[['diff']] <- ifelse(df[['white']] < df[[second_race]], 1, 0)
  
  # assign color to each row
  color_palette <- c('#4e79a7', '#f28e2b')
  df[['colors']] <- colorize(df[['diff']], color_palette)
  
  # tooltip
  scatter_tooltip <- "<b>{point.county_name}</b><br>
                      Stops per 100 residents (Black): <b>{point.black}</b><br>
                      Stops per 100 residents (White): <b>{point.white}</b><br>
                      Stops per 100 residents (Hispanic): <b>{point.hispanic}</b><br>
                      County population (2013): <b>{point.value_tooltip}</b><br>"
  
  df %>%
    hchart(
      "bubble", 
      hcaes(x = 'white', y = .data[[second_race]], size = value, color = colors)
    ) %>%
    hc_add_series(name = 'line',
                  data = data.frame(
                    x = seq(1, max_point, 1),
                    y = seq(1, max_point, 1),
                    type = 'line',
                    marker = list(enabled = FALSE)
                  )) %>%
    # remove tooltip for line
    hc_plotOptions(line = list(enableMouseTracking = FALSE),
                   bubble = list(opacity = .85,
                                 minSize = "1%", maxSize = "7%")) %>%
    hc_xAxis(min = 1, max = max_point, type = 'logarithmic',
             title = list(text = 'Stops per 100 residents for White drivers')) %>% 
    hc_yAxis(min = 1, max = max_point, type = 'logarithmic',
             title = list(text = y_title)) %>%
    hc_tooltip(
        headerFormat = "",
        pointFormat = scatter_tooltip
    ) %>%
    hc_title(text = plot_title)
}

# extract time from date time
time_to_minute <- function(time) {
  # minutes since midnight
  hour(time) * 60 + minute(time)
}
```



## Stops per 100 residents for black and white drivers

```{r importData, eval = F, cache = T}
# download entire state traffic stop dataset
nc_stops <- vroom('https://shane-datasets.nyc3.digitaloceanspaces.com/traffic-stop/nc/nc_statewide_2020_04_01.csv.gz',
                  col_select = -contains('raw'))

# get 2010 - 2013 5 year and aggregate
pop_years <- seq(2009, 2013, 1)

n_years <- length(pop_years)

nc_stops <- nc_stops %>%
  mutate(year = year(date)) %>%
  # only keep between years 2010 and 2013 
  # 2013 is final full year of stop data
  filter(year %in% !!pop_years)

nc_stops %>%
  group_by(year, county_name) %>%
  sample_frac(.20) %>%
  write_rds('nc_stops.rds')
```

```{r}
nc_stops <- read_rds('nc_stops.rds')
```

## Comparing Stops Per 100 Residents Among Racial Groups

```{r importCensus, cache = T}
# racial populations by county from census ----------------

# recode integers for dates to years
recode_date <- c(
  `3` = 2010,
  `4` = 2011,
  `5` = 2012,
  `6` = 2013,
  `7` = 2014,
  `8` = 2015
)

# get 2013 overall county populations
county_pop <- get_estimates(geography = "county", state = 'NC',
                            product = 'population', 
                            time_series = T,
                            year = 2018) %>%
  # only keep 2013 and only keep population (not density)
  filter(DATE == 6,
         variable == 'POP') %>%
  mutate(NAME = str_remove_all(NAME, ' County, North Carolina')) %>%
  select(NAME, value)

# import population data by county and race
county_pop_race <- get_estimates(geography = "county", state = 'NC',
                                product = 'characteristics', 
                                breakdown = c('RACE', 'HISP'),
                                breakdown_labels = T,
                                time_series = T,
                                year = 2018) 

# calculate aggregate percentage of population by race
county_pop_agg <- county_pop_race %>%
  # only keep 2010 - 2013
  filter(between(DATE, 3, 6)) %>%
  # aggregate population by race for each county
  group_by(GEOID, NAME, RACE, HISP) %>%
  summarize(agg_pop = sum(value)) %>%
  ungroup() %>%
  filter(HISP != 'Both Hispanic Origins') %>%
  # make the All Races  race that is Hisp the Hisp race
  mutate(RACE = ifelse(RACE == 'All races' & HISP == 'Hispanic', 'Hispanic', RACE)) %>%
  # only need white, black, and hispanic
  filter(RACE %in% c('White alone', 'Black alone', 'Hispanic'),
         # do not need hispanic breakdown by race
         RACE == 'Hispanic' | HISP == 'Non-Hispanic') %>%
  # remove 'alone' phrase from race
  mutate(RACE = str_remove_all(RACE, ' alone'),
         # make lower case and remove latino to match traffic stops
         RACE = str_to_lower(RACE),
         # remove string so that it matches with traffic stop data
         NAME = str_remove_all(NAME, ' County, North Carolina')) %>%
  # don't need the hispanic column anymore
  select(-HISP)
```

```{r stopsByRace}
# calculate stops per race --------------

# save list of stop reasons to be uses in text
stop_reasons <- unique(nc_stops$reason_for_stop)

stops_by_race <- nc_stops %>%
  # calculate number of stops by race (numerator)
  group_by(county_name, subject_race) %>%
  summarize(num_stops_race = n()) %>%
  # calculate percentage of stops by race
  ungroup() %>%
  # stops per 100 people
  #mutate(stops_per = (num_stops_race*100) / agg_pop) %>%
  # only need three races; not enough data for others
  filter(subject_race %in% c('black', 'white', 'hispanic')) %>%
  # only keep counties with a minimum of 100 stops for each race
  group_by(county_name) %>%
  mutate(min_num = min(num_stops_race)) %>%
  ungroup() %>%
  filter(min_num >= 500) %>%
  drop_na(county_name) %>%
  mutate(county_name = str_remove_all(county_name, ' County'),
         # correct spelling mistake
         county_name = str_replace(county_name, 'Tyrell', 'Tyrrell')) %>%
  drop_na(county_name) %>%
  # combine stops by race percentages and racial population percentages
  left_join(county_pop_agg, 
            by = c('county_name' = 'NAME', 'subject_race' = 'RACE')) %>%
  # number of stops per 100 people
  mutate(stops_per = round(num_stops_race / (agg_pop / 100), 2)) %>%
  # convert to wide form where each race is in a different column
  # needed for plotting
  pivot_wider(id_cols = 'county_name', 
              names_from = 'subject_race',
              values_from = "stops_per") %>%
  # combine county populations
  left_join(county_pop,
            by = c('county_name' = 'NAME')) %>%
  mutate(value_tooltip = number(value, accuracy = 1, big.mark = ',')) %>%
  # Alleghany is odd outlier, so remove
  filter(!county_name %in% c('Alleghany'))

```

```{r plotStopsRace}
# scatter plot of race and perc. stops compared to overall perc. pop.


bw_stops_title <- 'Stops Per 100 Residents for Black and White Drivers'
bw_y_title <- 'Stops per 100 residents for Black drivers'
bw_scatter_plot <- scatter_stops_per(stops_by_race, 'black', bw_stops_title, bw_y_title)

hw_stops_title <- 'Stops Per 100 Residents for Hispanic and White Drivers'
hw_y_title <- 'Stops per 100 residents for Hispanic drivers'
hw_scatter_plot <- scatter_stops_per(stops_by_race, 'hispanic', hw_stops_title, hw_y_title) %>%
  add_credits()

hw_grid(
  bw_scatter_plot, hw_scatter_plot,
  ncol = 2, rowheight = 300
)
```

## Veil Of Darkenss Test

```{r}
# get centroid of every county -----------------


# get county shapefiles and centroids
nc_counties <- counties(state = 'NC', cb = T)

# find centroid of each county by using it's boundaries
nc_counties$lon<-st_coordinates(st_centroid(nc_counties))[,1]
nc_counties$lat<-st_coordinates(st_centroid(nc_counties))[,2]

# drop shapefile column
nc_counties$geometry <- NULL

nc_counties <- nc_counties %>%
  ungroup() %>%
  select(GEOID, NAME, lon, lat)

# get sunlight times for each county

# extend dataset to include a county row for each day
# neede because function to calcualte sunset requires date column in dataframe
days_seq <- seq(as.Date(min(nc_stops$date)), as.Date(max(nc_stops$date)), "days")

nc_counties_sunset <- map_df(days_seq, function(day) {
  nc_counties %>%
    mutate(date = !!day) %>%
    getSunlightTimes(
      data = .,
      keep = c("sunset", "dusk"), 
      tz = 'EST'
    )
}) %>%
  mutate(
    sunset_minute = time_to_minute(sunset),
    dusk_minute = time_to_minute(dusk),
    date = ymd(str_sub(date, 1, 10))
) %>% 
  # join county names
  left_join(nc_counties, by = c('lon', 'lat'))
```

```{r}
# merge dusk times with nc stops dataset

# only keep the 20 most populated counties
most_pop_counties <- county_pop %>%
  arrange(desc(value)) %>%
  head(20) %>%
  .[[1]]

nc_stops_veil <- nc_stops %>%
  drop_na(time) %>%
  mutate(county_name = str_remove_all(county_name, ' County')) %>%
  # only keep the 20 most populated counties
  filter(county_name %in% !!most_pop_counties) %>%
  # add sunset and dusk times
  left_join(nc_counties_sunset, 
            by = c('county_name' = 'NAME', 'date')) %>%
  # convert date times to integer minutes from midnight
  mutate(
    minute = time_to_minute(time),
    minutes_after_dark = minute - dusk_minute,
    is_dark = minute > dusk_minute
  ) %>%
  ungroup() %>%
  group_by(county_name) %>%
  # find the min and max dusk times for each county
  mutate(
    min_dusk_minute = min(dusk_minute),
    max_dusk_minute = max(dusk_minute),
    is_black = subject_race == "black"
  ) %>% 
  filter(
    # Filter to get only the intertwilight period
    minute >= min_dusk_minute,
    minute <= max_dusk_minute,
    # Remove ambigous period between sunset and dusk
    !(minute > sunset_minute & minute < dusk_minute),
    # Compare only white and black drivers
    subject_race %in% c("black", "white")
  ) %>%
  select(date, time, sunset, dusk, contains('minute'), is_dark, everything()) %>%
  drop_na(is_black, is_dark, minute, subject_age, subject_sex, county_name) %>%
  mutate(county_name = factor(county_name),
         year = as.factor(year))
```

### BART ###

```{r}
# prediction dataset for all of NC

x_vars <- c('minute', 'subject_age',  'subject_sex', 'county_name', 'is_dark', 'year')

# training dataset (original data)
predictors <- nc_stops_veil %>%
  ungroup() %>%
  select(!!x_vars) %>%
  mutate(across(c('subject_sex', 'county_name', 'year'), ~as.factor(.))) %>%
  as.data.frame()

# save number of rows to use later
n <- nrow(predictors)

# dataset to create potential outcomes
# contains each column of the original dataset twice - one with dark, one with not-dark
test_data <- predictors %>%
  mutate(is_dark = T) %>%
  bind_rows(
    predictors %>%
      mutate(is_dark = F)
  )

response <- as.numeric(nc_stops_veil$is_black)

# prediction_df <- predictors %>%
#   data_grid(
#     minute = as.integer(seq_range(minute, n = 15, trim = .1)),
#     subject_age = 30,
#     subject_sex = subject_sex,
#     county_name = county_name,
#     is_dark = c(TRUE, FALSE),
#     year = year
#   ) %>%
#   mutate(across(c('subject_sex', 'county_name', 'year'), ~as.factor(.))) %>%
#   filter(subject_sex == 'male',
#          year == 2013) %>%
#   as.data.frame()

bart_mod <- mc.pbart(
  x.train = predictors, 
  y.train = response, 
  x.test = test_data, 
  ndpost = 200, 
  mc.cores = 4,
  cont = FALSE,
  seed = 99
)

posterior_predictions <- as.data.frame(bart_mod$prob.test)
```

```{r}
a <- data.frame(
  a = round(rnorm(10, 0, 5), 0),
  b = round(rnorm(10, 0, 5), 0)
)

b <- data.frame(
  a = round(rnorm(10, 0, 5), 0),
  b = round(rnorm(10, 0, 5), 0)
)

# find most likely difference in probability driver is black when comparing before and after sunset
n_test_end <- nrow(test_data)
n_test_start <- n+1

post_pred_outcomes <- posterior_predictions[1:n] - posterior_predictions[n_test_start:n_test_end]
```

```{r}
# find the difference between 

avg_prob_is_black <- function(pred_matrix, vec_with_dark, use_dark_cols) {
  
  pred_df <- as.data.frame(pred_matrix)
  
  pred_df <- pred_df[vec_with_dark == use_dark_cols]
  
  pred_df %>%
    summarize_all(mean) %>%
    as_vector()
}

# mean difference in dark
post_dark <- avg_prob_is_black(county_predictions, nc_stops_veil$is_dark, T)
post_light <- avg_prob_is_black(county_predictions, nc_stops_veil$is_dark, F)
post_diff <- post_dark - post_light

county_df <- as.data.frame(county_predictions)

```

```{r}
# plots of counties and difference in probability black
# between night and not night
# in the prediction dataset, odd numbers are not dark, even numbers are dark
identifying_columns <- c('minute', 'county_name', 'is_dark')

county_posterior_hdi <- county_predictions %>%
  t() %>%
  as.data.frame() %>%
  bind_cols(prediction_df[identifying_columns]) %>%
  pivot_longer(cols = V1:V200, 
               names_to = 'names', values_to = 'values') %>%
  county_posterior_long %>%
  group_by_at(identifying_columns) %>%
  median_hdci(values, .width = c(.95, .5)) %>%
  pivot_wider(id_cols = c(identifying_columns, 'values') , 
              names_from = '.width', values_from = c('.lower', '.upper'))

```

```{r}
# plot
ggplot(county_posterior_hdi, aes(minute, values, color = is_dark)) +
  geom_line() +
  facet_wrap(~county_name)
```



## Logistic Regression

```{r}
t_prior <- student_t(df = 7, location = 0, scale = 2.5)

log_mod <- stan_glmer(
  is_black ~ is_dark + splines::ns(minute, df = 4) + subject_age + subject_sex + (1 |county_name) + (1 | year), 
  data = nc_stops_veil,
  family = binomial(link = "logit"), 
  prior = t_prior, 
  prior_intercept = t_prior, 
  QR=TRUE,
  seed = 909
)

write_rds(log_mod, 'log_mod.rds')
```