---
title: "A First Attempt at Bayesian Mediation Analysis"
author: "Shane Orr"
date: '2020-11-25'
output:
  html_document:
    df_print: paged
categories:
- bayesian analysis
- mediation analysis
tags: []
subtitle: The same process and 'almost' the same results as non-Bayesian approaches,
  but cooler
summary: ''
authors: []
lastmod: '2020-11-25T18:38:02-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
links:
- icon: github
  icon_pack: fab
  name: Github
  url: https://github.com/shanejorr/shanes-site/blob/main/content/post/2020-11-25-bayesian-mediation-analysis/index.en.Rmd
draft: yes
slug: bayesian-mediation-analysis
---

```{r setup, echo = F}
knitr::opts_chunk$set(echo = T,
                      message = F,
                      warning = F,
                      error = F)
```

## What is mediation analysis? {#introduction}

Let's say you want to examine the affect of employment on whether a student passes a class. You set up a cruel randomized controlled trial where some students are forced to work 15 hours a week and other are prohibited from working at all. You speculate that working students will perform worse because they have less time to study.

We can visually depict the causal relationships with the following Directed Acyclic Graph (DAG):

```{r mainDag, fig.cap = 'DAG highlighting the effect of working on passing a class', out.width = '50%'}
knitr::include_graphics(glue::glue("dag/working_dag_main.png"))
```

As the graph shows, we might be interested in three different ways that working affects the probability of passing a class.

1.  *Direct Effect:* The direct effect is the effect that working has on class passage through a direct causal link. There is no intermediate cause between working and passing the class; at least none that we can measure.

2.  *Indirect Effect:* In our example, working's indirect effect on bar passage is its effect through hours studied. Working impacts hours studied and hours studied affects class passage.

3.  *Total Effect:* Total effect is the overall, all things considered, effect of working on passing. It's the direct effect plus the indirect effect.

The goal of mediation analysis is to disentangle these three effects.

THis post is my attempt to manually code a mediation analysis. There are packages that do it for you but I could not find one to fit my use case: mediation analysis using a Bayesian hierarchical logistic regression model and a Bayesian hierarchical linear regression. So, let's see if I can do it on my own!

Let's get set up with packages and a series of functions that I will repeatedly use.

```{r loadPackages}
library(rstanarm)
library(mediation)
library(tidybayes)
library(glue)
library(knitr)
library(ggeffects)
library(knitr)
library(tidyverse)

# stan options
# detect and use max number of cores
options(mc.cores = parallel::detectCores())

# create ggplot theme for this post
post_theme <- theme_minimal() +
  theme(legend.position = 'bottom',
        plot.title = element_text(size = 10),
        axis.title = element_text(size = 10))

theme_set(post_theme)

# set folder to import pictures
dag_folder <- "content/post/2020-11-25-bayesian-mediation-analysis/dag"
```


```{r customFunctions}
relabel_plot_color <- scale_fill_brewer(palette = "Set2", type = "Qual", labels = c(`0`= "Working", `1` = "Not working"))

posterior_diff <- function(mod, new_df, effect_type) {
  
  # create one column dataframe that is the difference in linear predictions for working and non-working students
  # parameters:
  #   mod: model
  #   new_df: dataframe to create predictions from
  #   effect_type: type of effect (indirect, direct, total)

  mod_post <- posterior_linpred(mod, newdata = new_df, transform = T,
                              seed = 1837, n = 500) %>%
    as.data.frame()
  
  col_split <- ncol(mod_post)/2
  
  mod_diff <- unlist(mod_post[1:col_split] - mod_post[(col_split+1):ncol(mod_post)])
  
  diff <- data.frame(diff = mod_diff,
                     type_effect = effect_type)
  
  return(diff)
}

posterior_diff_plot <- function(post_diff, x_limits, plot_title)  {
  
  # plot posterior distribution of difference in working and no-working predictions
  # parameters:
  #   post_diff: dataframe created from posterior_diff with predicted posterior 
  #     difference between workers and non-workers
  #   x_limits: plot x limits
  #   plot_title: title of plot
  
  ggplot(post_diff, aes(x =diff*100)) +
    stat_halfeye(alpha = .7) +
    scale_x_continuous(limits = x_limits) +
    labs(title = plot_title,
         x = 'Perc. point difference in probability of passing class\nNot working - working',
         y = 'Density',
         fill = NULL)
}

two_group_plot <- function(df, plot_title) {
  
  # plot posterior distribution of both workers and non-workers
  # parameters:
  #   df: dataframe for plotting; will be linear predictions for workers and non-workers
  #   plot_title: title of plot
  
  ggplot(df, aes(x = .value, fill = as.factor(work))) +
    stat_halfeye(alpha = .8) +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    relabel_plot_color +
    labs(title = plot_title,
         x = 'Probability of passing class',
         y = 'Density',
         fill = NULL)
}
```

## Untangling the Gordian Effects Knot

We'll simulate a data set to show the three types of effects outlined in the [introduction](#introduction). The fake data set includes three columns: (1) a 0 or 1 identifying whether the student worked, (2) a continuous number showing how many hours the student studied in the given week, and (3) a 0 or 1 signifying whether the student passed the class.

The code below creates the fake data.

```{r createDataset}
# create simulated dataset --------

# number of rows in dataset
n <- 500

# 1 if student does not work, 0 if student works
work_order <- c(1, 0)
working <- rep(work_order, times = n/2)

# save for future use
work_string <- c('Working', 'Not working')

# create vector for hours studied that depends on whether the student worked
set.seed(2938)
study_hours <- rnorm(n, 
                     mean = 25 + (working*5),
                     sd = 10)

# create vector for passing the class
# value depends on both hours studied and whether the student worked
final_grade_formula <- (.05 + .015*study_hours + .04*working)
final_grade <- rnorm(n, mean = final_grade_formula, sd = .05)
final_grade <- ifelse(final_grade > 1, 1, final_grade)
final_grade <- ifelse(final_grade < 0, 0, final_grade)
final_grade <- rbinom(n = n, size = 1, prob = final_grade)

grades <- data.frame(
  work = working,
  study = study_hours,
  pass = final_grade
)
```

Here's a sample of the data set.

```{r}

kable(head(grades), digits = 2)
```

### Calcualting the direct effect the old fashioned way

In figure \@ref(fig:mainDag), the direct effect of working on passing the class is the causal line that does not go through hours studied. We calculate this through a single model that conditions on hours studied. By conditioning on hours studied, we block the path from working to course passage that flows through hours studied. This only leaves the direct effect path open.

```{r directDag, fig.cap = 'DAG highlighting the direct effect of working on passing a class', out.width = '50%'}
knitr::include_graphics("dag/working_dag_direct.jpg")
```

By conditioning on hours studied, the effect of working on passing represents the effect with hours studied being the same for both the working and non-working groups. We thus remove any effect working has on passage via creating differences in hours studied between workers and non-workers.

We can isolate the direct effect through a simple Bayesian logistic regression model with hours study and working status as predictors and whether the student passed as the response. By including hours worked as a predictor, we hold it constant when examining the relatinship between working and passing the class. The working regression coefficient then drives the direct effect.

```{r deMod, cache = T}
# logistic regression model to identify direct effect
full_mod <- stan_glm(pass ~ study + work, 
                     family = binomial('logit'),
                     seed = 938,
                     data = grades)

```

With our model in hand, we can now visualize the direct effect. One way is to predict class passage for workers and non-workers, while holding hours studied constant. In other words, we can use the model to predict class passage for the two following hypothetical students. The hours worked is the mean hours worked in our simulated data.

```{r}
# predictio ndataset
mean_hours <- mean(grades$study)

direct_prediction <- data.frame(
  work = work_order,
  study = mean_hours
)
```

Here is the posterior distribution of the probability of passing the class, grouped by whether students worked. We assume all students studied `r (mean_hours)` hours, the mean amount.

```{r dePlotDiff, fig.caption = "Direct effect: Difference in class passage probabilities between workers and non-workers, with hours studied held constant.", fig.height = 2.7, fig.width = 4}
full_mod %>%
  add_fitted_draws(newdata = direct_prediction, seed = 93, n = 300) %>%
  two_group_plot(glue("Prob. of Passing based on Work Status\nHours studied held constant at {round(mean_hours, 2)} Hours"))
```

We see that students who worked and a lower probability of passing the class compared to non-workers, even when accounting for hours studied. But, there is overlap in the probability distributions. 

We can better highlight the difference and uncertainty through the following steps:

1.  Create two posterior predictive distributions for passing the class for each student: one assuming the student worked and another assuming the student did not work.
2.  For each set of predictions (each student), subtract the posterior predictive distribution arising when the student works from the distribution occurring when the student does not work.

```{r}
# for each student (observations) create two predictions for passing the class, one if the student worked
# and anotehr if the student did not work

full_mod_newdata <- expand_grid(study = grades$study,
                                work = work_order) %>%
  arrange(desc(work), study) %>%
  as.data.frame()

# find differences in posterior distributions
direct_effect_post <- full_mod %>%
  posterior_diff(new_df = full_mod_newdata, effect_type = 'Direct Effect')
```

This difference is shown below. It gives us the posterior predictive distribution of the difference in passing the class between workers and non-workers, holding hours studied constant. It aligns with figure \@ref(fig:dePlotDiff), but puts more contours on the magnitude of the difference and its uncertainty. 

```{r iePlotDiff, fig.cap = "Direct effect of working on passing the class.", fig.height = 2.5, fig.width = 4}
posterior_diff_plot(direct_effect_post, x_limits = c(-15, 30), plot_title = 'Direct Effect of Working on Passing')
```

This gives us a much better picture of the difference in class passage probabilities between workers and non-workers. And we can also use the posterior distribution of differences to calculate probabilities such as the probability that the direct effect is positive.

### Total effect the old fashioned way

The total effect is the effect of working on class passage through all causal links originating with working. In figure \@ref(fig:mainDag), its the effect that goes straight from working to class passage and the effect that runs through hours studied. We calculate this effect by failing to condition on hours studied. By removing hours studied from the equation, the effect that previously traveled through hours studied now goes directly to class passage. This allows us to merge the two lines into one.

```{r teDag, fig.cap = 'DAG highlighting the effect of working on passing a class', out.width = '50%'}
knitr::include_graphics("dag/working_dag_total.png")
```

We can estimate the total effect by a Bayesian logistic regression model with work status as the lone predictor and class passage as the response.

```{r teMod, cache = T}
# total effect model
total_effect <- stan_glm(pass ~ work, 
                         family = binomial('logit'),
                         seed = 938,
                         data = grades)
```

As with the direct effect, we can plot the posterior predictive distributions of workers and non-workers.

```{r tePlotPosterior, fig.height = 3, fig.width = 4}
total_effect %>%
  add_fitted_draws(newdata = data.frame(work = work_order), seed = 93, n = 300) %>%
  two_group_plot('Prob. of Passing based on Work Status')
```

We can also focus on the difference and calculate the posterior predictive distribution representing the difference in class passage between workers and non-workers.

```{r tePlotDiff, fig.height = 2.5, fig.width = 4}
diff_limits <- c(-10, 35)

total_effect_post <- total_effect %>%
  posterior_diff(new_df = data.frame(work = work_order), effect_type = 'Total Effect')

posterior_diff_plot(total_effect_post, x_limits = diff_limits, plot_title = 'Total Effect of Working on Passing')
```

The total effect shown in figure \@ref(fig:tePlotDiff) is larger than the direct effect from figure \@ref(fig:tePlotDiff). This is expected. The total effect includes the effect of studying on passage, while the direct effect does not. Since this effect is positive, we would expect the total effect to be larger.

### Indirect effect (kind-of) the old fashioned way

Calculating the indirect effect is more challenging. We want to calculate the effect of working on passing the class that arises because of the effect of working on number of hours studied. Our speculation on the indirect effect is that working causes students to study less, which then leads to them being less likely to pass the class.

Here's how the authors of mediation method used here describe calculating indirect effects:

> First, we fit regression models for the mediator and outcome. The mediator is modeled as a function of the treatment and any relevant pretreatment covariates. The outcome is modeled as a function of the mediator, the treatment, and the pretreatment covariates. The form of these models is immaterial. ... Based on the mediator model, we then generate two sets of predictions for the mediator, one under the treatment and the other under the control. For example, in the media framing study, this would correspond to predicted levels of anxiety after reading a news story on immigration or a neutral news story. 

> For the next step, the outcome model is used to make potential outcome predictions. ... First, the outcome is predicted under the treatment using the value of the mediator predicted in the treatment condition. Second, the outcome is predicted under the treatment condition but now uses the mediator prediction from the control condition. The ACME is then computed as the average difference between the outcome predictions using the two different values of the mediator.[^Imai, K., Keele, L., Tingley, D., & Yamamoto, T. (2011). Unpacking the black box of causality: Learning about causal mechanisms from experimental and observational studies. American Political Science Review, 765-789.]

Taking our cue from the method's source, we'll proceed in two steps: (1) fit models, and (2) make potential outcome predictions.

#### Step 1: Fitting regression models

The first step is the easiest. We'll start by fitting two models:

1.  Mediator model: The mediator, number of hours studied, as the response and the treatment, working, as the predictor.
2.  Outcome model: The outcome, passing the class, as the response and the mediator and treatment, hours studied and working, as the predictors.

We'll then create two sets of predictions from the mediator model, one for working students and another for non-working students.

##### Mediator model

Here is our simple mediator model.

```{r mediatorModel, cache = T}
mediator_model <- stan_glm(study ~ work, 
                           family = 'gaussian',
                           seed = 938,
                           data = grades)
```

##### Outcome model

And here is the almost equally simple outcome model.

```{r outcomeModel, cache = T}
outcome_model <- stan_glm(pass ~ work + study, 
                          family = binomial('logit'),
                          seed = 938,
                          data = grades)
```

##### Predictions from mediator model

Now, we'll generate predictions from the mediator models. We'll predict hours studied for both workers and non-workers.

```{r}
# dataset that only includes two rows, one for a worker and one for a non-worker
mediation_predict_dataset <- data.frame(work = work_order)

mediator_mod_predictions <- add_fitted_draws(newdata = mediation_predict_dataset, 
                                             model = mediator_model,
                                             value = 'study',
                                             n = 500,
                                             seed = 1837)
```

#### Step 2: Create potential outcome predictions

This is where things get challenging. We want to prediction the outcome, passing the class, using the full outcome model from the predictions created by the mediator model. Bayesian predictions, however, are not point estimates. They are the full posterior distribution of predicted probabilities. By creating predictions for workers and non-workers - two predictions - and specifying 500 draws from the posterior distribution - using `n = 500` in `add_fitted_draws` - we now have 1,000 separate predictions of hours studied. We have 500 for workers and 500 for non-workers. We'll feed all 1,000 hours studied values to the outcome model and make predictions of passing the class from these 1,000 predictions. And all 1,000 values will be assumed to come for workers. I'm sure that sounds convoluted, so here's the code.

```{r}
outcome_mod_predictions <- mediator_mod_predictions %>%
  # save the work value from the mediation model because we need to take the difference between the predictions
  # for workers and non-workers as specified in the mediation model
  mutate(work_mediator = work,
         # make all predicted values come from non-workers
         work = 1) %>%
  select(work_mediator, work, study) %>%
  add_fitted_draws(model = outcome_model,
                   n = 500,
                   seed = 1837) %>%
  ungroup() %>%
  arrange(.row, .draw, work_mediator)
```

Finally, we calculate the difference in the probability of passing between workers and non-workers in the original mediation model.

```{r}

working_work_mediator <- outcome_mod_predictions %>%
  filter(work_mediator == 0) %>%
  arrange(.row, .draw) %>%
  rename(working_pass = .value, working_study = study)

nonworking_work_mediator <- outcome_mod_predictions %>%
  filter(work_mediator == 1) %>%
  arrange(.row, .draw) %>%
  select(nonworking_pass = .value, nonworking_study = study) 

mediation_predictions <- working_work_mediator %>%
  bind_cols(nonworking_work_mediator) %>%
  select(.row:working_study, nonworking_study, everything()) %>%
  mutate(diff = nonworking_pass - working_pass,
         type_effect = 'Indirect Effect')
```

All this complete, here is the posterior predictive distribution of our indirect effects.

```{r ieEffectPlot, fig.height = 2.5, fig.width = 4}
posterior_diff_plot(mediation_predictions, x_limits = c(0, 25), plot_title = 'Indirect Effect of Working on Passing')
```

### Compare results to `mediation` package

```{r}
med_fit <- lm(study ~ work, data = grades)

out_fit <- glm(pass ~ work + study,
              data = grades, family = binomial("logit"))

med_out <- mediate(med_fit, out_fit, treat = "work", mediator = "study",
                  robustSE = TRUE, sims = 500)

# get estimates and cnof. intervals for frequentist effect size estimates with mediation package

# dataframe of confidence intervals, with two columns (one for lower and upper bounds)
# will be used for plotting effect sizes
upper_lower_ci <- bind_rows(med_out$z.avg.ci, med_out$d.avg.ci, med_out$tau.ci)

mediation_effects <- tibble(
  effect_type = c('Direct Effect', 'Indirect Effect', 'Total Effect'),
  effect_size = c(med_out$z.avg, med_out$d.avg, med_out$tau.coef),
  lower_ci = upper_lower_ci[[1]],
  upper_ci = upper_lower_ci[[2]],
  effect_group = 'Frequentist (mediation package)'
)
```


```{r}
# get 95% credible intervals for bayesian effects
bayes_effect <- bind_rows(list(direct_effect_post, mediation_predictions, total_effect_post)) %>%
  group_by(type_effect) %>%
  median_hdi(diff)
```

```{r raceMediation, fig.cap = "Direct, indirect, and total effects of working on class passage. Values are the average percentage point difference in class passage.", fig.height = 3.5, fig.width = 5}
bayes_effect %>%
  select(effect_type = type_effect, effect_size = diff, lower_ci = .lower, upper_ci = .upper) %>%
  mutate(effect_group = "Bayesian Mediation") %>%
  bind_rows(mediation_effects) %>%
    ggplot(aes(effect_size, fct_rev(effect_type), color = effect_group)) +
    geom_point() +
    geom_segment(aes(x = lower_ci, xend = upper_ci, yend = effect_type)) +
    geom_vline(xintercept = 0, alpha = .6) +
    scale_color_brewer(palette = "Set2", type = "Qual") +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    facet_wrap(~effect_group, ncol = 1) +
    labs(title = 'Cumulative Effects of Race on Bar Passage',
           x = "Percentage point difference (Non-workers minus Workers)\nIn avg. probability of class passage",
           y = NULL) +
    theme(legend.position = 'none')
```

## The versitility of mediation analysis