---
title: Using Bayesian Additive Regression Trees to Analyze Traffic Stop Discrimination
author: ''
date: '2021-03-08'
slug: using-bayesian-additive-regression-trees-to-analyze-traffic-stop-discrimination
categories:
  - bayesian analysis
  - traffic stops
  - Bayesian Additive Regression Trees
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-03-08T19:22:36-05:00'
featured: no
image:
  caption: '<span>Photo by <a href="https://unsplash.com/@gerandeklerk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Geran de Klerk</a> on <a href="https://unsplash.com/s/photos/forest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>'
  focal_point: ''
  preview_only: no
projects: []
links:
- icon: github
  icon_pack: fab
  name: Github
  url: https://github.com/shanejorr/shanes-site/blob/main/content/post/2021-03-08-using-bayesian-additive-regression-trees-to-analyze-traffic-stop-discrimination/index.en.Rmd
draft: yes
---

```{r setup, echo = F}
knitr::opts_chunk$set(echo = T,
                      message = F,
                      warning = F,
                      error = F)
```

```{r importLibraries}
library(glue)
library(vroom)
library(modelr)
library(tidycensus)
library(lubridate)
library(highcharter)
library(scales)
library(widgetframe)
library(suncalc)
library(tigris)
library(sf)
library(bartCause)
library(tidybayes)
library(lme4)
library(tidyverse)
```

```{r customFunctions}
# custom functions --------------------------

# create ggplot theme for this post
post_theme <- theme_minimal() +
  theme(legend.position = 'bottom',
        plot.title = element_text(size = 11),
        plot.subtitle = element_text(size = 10),
        axis.title = element_text(size = 10))

theme_set(post_theme)

# standard credits to all to all high charts plots

# credits to be used on all plots
add_credits <- function(hc) {
  hc %>%
    hc_credits(
      enabled = TRUE,
      text = "Data source: The Stanford Open Policing Project | US Census Bureau Pop. Estimates",
      href = FALSE
  )
}

scatter_stops_per <- function(df, second_race, plot_title, y_title) {
  
  # scatter plot of stops per 100 residents for white and black / hispanic drivers
  # second_race is the race to compare with white
  
  # max axis point
  max_point <- 45
  
  # find out if white or minority group is higher, used for colors above or below line
  df[['diff']] <- ifelse(df[['white']] < df[[second_race]], 1, 0)
  
  # assign color to each row
  color_palette <- c('#4e79a7', '#f28e2b')
  df[['colors']] <- colorize(df[['diff']], color_palette)
  
  # tooltip
  scatter_tooltip <- "<b>{point.county_name}</b><br>
                      Stops per 100 residents (Black): <b>{point.black}</b><br>
                      Stops per 100 residents (White): <b>{point.white}</b><br>
                      Stops per 100 residents (Hispanic): <b>{point.hispanic}</b><br>
                      County population (2013): <b>{point.value_tooltip}</b><br>"
  
  df %>%
    hchart(
      "bubble", 
      hcaes(x = 'white', y = .data[[second_race]], size = value, color = colors)
    ) %>%
    hc_add_series(name = 'line',
                  data = data.frame(
                    x = seq(1, max_point, 1),
                    y = seq(1, max_point, 1),
                    type = 'line',
                    marker = list(enabled = FALSE)
                  )) %>%
    # remove tooltip for line
    hc_plotOptions(line = list(enableMouseTracking = FALSE),
                   bubble = list(opacity = .85,
                                 minSize = "1%", maxSize = "7%")) %>%
    hc_xAxis(min = 1, max = max_point, type = 'logarithmic',
             title = list(text = 'Stops per 100 residents for White drivers')) %>% 
    hc_yAxis(min = 1, max = max_point, type = 'logarithmic',
             title = list(text = y_title)) %>%
    hc_tooltip(
        headerFormat = "",
        pointFormat = scatter_tooltip
    ) %>%
    hc_title(text = plot_title)
}

# extract time from date time
time_to_minute <- function(time) {
  # minutes since midnight
  hour(time) * 60 + minute(time)
}

create_train_test_sets <- function(split_partition, predictor_variables, train_or_test = 'train') {
  
  # create train and testing datasets
  
  if (train_or_test == 'train') {
    
    pred_df <- training(split_partition)
    
  } else if (train_or_test == 'test') {
    
    pred_df <- testing(split_partition)
    
  } else {
    stop("train_or_test must be either 'train' or 'test'")
  }
  
  pred_df %>%
      ungroup() %>%
      # only keep predictors (required for BART)
      select(!!predictor_variables) %>%
      as.data.frame()
  
}
```



## Stops per 100 residents for black and white drivers

```{r importData, cache = T}
# downlaod traffic stop data --------------------------

# download entire state traffic stop dataset
nc_stops <- vroom('https://shane-datasets.nyc3.digitaloceanspaces.com/traffic-stop/nc/nc_statewide_2020_04_01.csv.gz',
                  col_select = -contains('raw'))

# get 2010 - 2013 5 year and aggregate
pop_years <- seq(2009, 2013, 1)

n_years <- length(pop_years)

nc_stops <- nc_stops %>%
  mutate(year = year(date)) %>%
  # only keep between years 2010 and 2013 
  # 2013 is final full year of stop data
  filter(year %in% !!pop_years)
```

## Comparing Stops Per 100 Residents Among Racial Groups

```{r importCensus, cache = T}
# racial populations by county from census ----------------

# recode integers for dates to years
recode_date <- c(
  `3` = 2010,
  `4` = 2011,
  `5` = 2012,
  `6` = 2013,
  `7` = 2014,
  `8` = 2015
)

# get 2013 overall county populations
county_pop <- get_estimates(geography = "county", state = 'NC',
                            product = 'population', 
                            time_series = T,
                            year = 2018) %>%
  # only keep 2013 and only keep population (not density)
  filter(DATE == 6,
         variable == 'POP') %>%
  mutate(NAME = str_remove_all(NAME, ' County, North Carolina')) %>%
  select(NAME, value)

# import population data by county and race
county_pop_race <- get_estimates(geography = "county", state = 'NC',
                                product = 'characteristics', 
                                breakdown = c('RACE', 'HISP'),
                                breakdown_labels = T,
                                time_series = T,
                                year = 2018) 

# calculate aggregate percentage of population by race
county_pop_agg <- county_pop_race %>%
  # only keep 2010 - 2013
  filter(between(DATE, 3, 6)) %>%
  # aggregate population by race for each county
  group_by(GEOID, NAME, RACE, HISP) %>%
  summarize(agg_pop = sum(value)) %>%
  ungroup() %>%
  filter(HISP != 'Both Hispanic Origins') %>%
  # make the All Races  race that is Hisp the Hisp race
  mutate(RACE = ifelse(RACE == 'All races' & HISP == 'Hispanic', 'Hispanic', RACE)) %>%
  # only need white, black, and hispanic
  filter(RACE %in% c('White alone', 'Black alone', 'Hispanic'),
         # do not need hispanic breakdown by race
         RACE == 'Hispanic' | HISP == 'Non-Hispanic') %>%
  # remove 'alone' phrase from race
  mutate(RACE = str_remove_all(RACE, ' alone'),
         # make lower case and remove latino to match traffic stops
         RACE = str_to_lower(RACE),
         # remove string so that it matches with traffic stop data
         NAME = str_remove_all(NAME, ' County, North Carolina')) %>%
  # don't need the hispanic column anymore
  select(-HISP)
```

```{r stopsByRace}
# calculate stops per race --------------

# save list of stop reasons to be uses in text
stop_reasons <- unique(nc_stops$reason_for_stop)

stops_by_race <- nc_stops %>%
  # calculate number of stops by race (numerator)
  group_by(county_name, subject_race) %>%
  summarize(num_stops_race = n()) %>%
  # calculate percentage of stops by race
  ungroup() %>%
  # stops per 100 people
  #mutate(stops_per = (num_stops_race*100) / agg_pop) %>%
  # only need three races; not enough data for others
  filter(subject_race %in% c('black', 'white', 'hispanic')) %>%
  # only keep counties with a minimum of 100 stops for each race
  group_by(county_name) %>%
  mutate(min_num = min(num_stops_race)) %>%
  ungroup() %>%
  filter(min_num >= 500) %>%
  drop_na(county_name) %>%
  mutate(county_name = str_remove_all(county_name, ' County'),
         # correct spelling mistake
         county_name = str_replace(county_name, 'Tyrell', 'Tyrrell')) %>%
  drop_na(county_name) %>%
  # combine stops by race percentages and racial population percentages
  left_join(county_pop_agg, 
            by = c('county_name' = 'NAME', 'subject_race' = 'RACE')) %>%
  # number of stops per 100 people
  mutate(stops_per = round(num_stops_race / (agg_pop / 100), 2)) %>%
  # convert to wide form where each race is in a different column
  # needed for plotting
  pivot_wider(id_cols = 'county_name', 
              names_from = 'subject_race',
              values_from = "stops_per") %>%
  # combine county populations
  left_join(county_pop,
            by = c('county_name' = 'NAME')) %>%
  mutate(value_tooltip = number(value, accuracy = 1, big.mark = ',')) %>%
  # Alleghany is odd outlier, so remove
  filter(!county_name %in% c('Alleghany'))

```

```{r plotStopsRace}
# scatter plot of race and perc. stops compared to overall perc. pop ----------


bw_stops_title <- 'Stops Per 100 Residents for Black and White Drivers'
bw_y_title <- 'Stops per 100 residents for Black drivers'
bw_scatter_plot <- scatter_stops_per(stops_by_race, 'black', bw_stops_title, bw_y_title)

hw_stops_title <- 'Stops Per 100 Residents for Hispanic and White Drivers'
hw_y_title <- 'Stops per 100 residents for Hispanic drivers'
hw_scatter_plot <- scatter_stops_per(stops_by_race, 'hispanic', hw_stops_title, hw_y_title) %>%
  add_credits()

hw_grid(
  bw_scatter_plot, hw_scatter_plot,
  ncol = 2, rowheight = 300
)
```

## Veil Of Darkenss Test

```{r minutesToDuskDataset}
# create dataset for veil of darkness test -----------------------

# get centroid of every county

# get county shapefiles and centroids
nc_counties <- counties(state = 'NC', cb = T)

# find centroid of each county by using it's boundaries
nc_counties$lon<-st_coordinates(st_centroid(nc_counties))[,1]
nc_counties$lat<-st_coordinates(st_centroid(nc_counties))[,2]

# drop shapefile column
nc_counties$geometry <- NULL

nc_counties <- nc_counties %>%
  ungroup() %>%
  select(GEOID, NAME, lon, lat)

# get sunlight times for each county

# extend dataset to include a county row for each day
# neede because function to calcualte sunset requires date column in dataframe
days_seq <- seq(as.Date(min(nc_stops$date)), as.Date(max(nc_stops$date)), "days")

nc_counties_sunset <- map_df(days_seq, function(day) {
  nc_counties %>%
    mutate(date = !!day) %>%
    getSunlightTimes(
      data = .,
      keep = c("sunset", "dusk"), 
      tz = 'EST'
    )
}) %>%
  mutate(
    sunset_minute = time_to_minute(sunset),
    dusk_minute = time_to_minute(dusk),
    date = ymd(str_sub(date, 1, 10))
) %>% 
  # join county names
  left_join(nc_counties, by = c('lon', 'lat'))

# only keep the 20 most populated counties
most_pop_counties <- county_pop %>%
  arrange(desc(value)) %>%
  head(20) %>%
  .[[1]]

# merge dusk times with nc stops dataset
nc_stops_veil <- nc_stops %>%
  drop_na(time) %>%
  mutate(county_name = str_remove_all(county_name, ' County')) %>%
  # only keep the 20 most populated counties
  filter(county_name %in% !!most_pop_counties) %>%
  # add sunset and dusk times
  left_join(nc_counties_sunset, 
            by = c('county_name' = 'NAME', 'date')) %>%
  # convert date times to integer minutes from midnight
  mutate(
    minute = time_to_minute(time),
    minutes_after_dark = minute - dusk_minute,
    is_dark = minute > dusk_minute
  ) %>%
  ungroup() %>%
  group_by(county_name) %>%
  # find the min and max dusk times for each county
  mutate(
    min_dusk_minute = min(dusk_minute),
    max_dusk_minute = max(dusk_minute),
    is_black = subject_race == "black"
  ) %>% 
  filter(
    # Filter to get only the intertwilight period
    minute >= min_dusk_minute,
    minute <= max_dusk_minute,
    # Remove ambigous period between sunset and dusk
    !(minute > sunset_minute & minute < dusk_minute),
    # Compare only white and black drivers
    subject_race %in% c("black", "white")
  ) %>%
  select(date, time, sunset, dusk, contains('minute'), is_dark, everything()) %>%
  drop_na(is_black, is_dark, minute, subject_age, subject_sex, county_name) %>%
  mutate(county_name = factor(county_name),
         year = as.factor(year))

# remove items to save RAM
rm(county_pop_race)
rm(nc_stops)
rm(nc_counties_sunset)
gc()
```

## BART Causal Model


```{r bartDataset}
# Bart model for all counties ---------------------
bart_mod <- bartc(
  response = is_black,
  treatment = is_dark,
  confounders = minute + subject_age + subject_sex + county_name,
  data = nc_stops_veil,
  estimand = 'ate',
  n.chains = 8
)
```

```{r bartCtyAte}
# Bart mdoels by county -------------------------

# initialize dataframe to store ates
bart_cty_ates <- summary(bart_mod)

bart_cty_ates <- overall_ate[[9]] %>%
  mutate(county = 'All Counties')

# iterate through each county, filter for data that only includes county, run BART model
for (cty in most_pop_counties) {
  
  # status update
  print(cty)
  
  # only keep needed county
  county_df <- nc_stops_veil %>%
    filter(county_name == !!cty)
  
  bart_mod_cty <- bartc(
    response = is_black,
    treatment = is_dark,
    confounders = minute + subject_age + subject_sex,
    data = county_df,
    estimand = 'ate',
    n.chains = 4
  )
  
  cty_ate <- summary(bart_mod_cty)

  cty_ate <- cty_ate[[9]] %>%
    mutate(county_name = !!cty)
  
  print(cty_ate)
  
  bart_cty_ates <- bart_cty_ates %>%
    bind_rows(cty_ate)
  
  print(bart_cty_ates)
  
  write_csv(bart_cty_ates, 'bart_cty_ates.csv')
  
  rm(bart_mod_cty)
  
}
```

## Logistic regression model as a check

```{r}
# logistic regression model with LMER
nc_stops_veil <- nc_stops_veil %>%
  ungroup() %>%
  # scale continuous predictors
  mutate(minute_scale = scale(minute),
         age_scale = scale(subject_age))

lmer_mod <- glmer(
  is_black ~ is_dark + minute_scale + age_scale + subject_sex + (1 | county_name) + (1 | year),
  data = nc_stops_veil,
  family = binomial(link = "logit")
)

names(summary(lmer_mod))

summary(lmer_mod)$coefficients %>%
  as.data.frame() %>%
  mutate(ci.lower = Estimate - (`Std. Error` * 1.96),
         ci.upper = Estimate + (`Std. Error` * 1.96)) %>%
  rownames_to_column() %>%
  filter(rowname == 'is_darkTRUE') %>%
  mutate(county_name = '20 Largest NC Counties') %>%
  select(county_name, Estimate, `Std. Error`, starts_with('ci')) %>%
  mutate(across(where(is.numeric), ~round(., 3)))
```